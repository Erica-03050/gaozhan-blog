#!/usr/bin/env python3
"""
æ­£ç¡®è·å–HTMLæ ¼å¼æ–‡ç« å†…å®¹
ä½¿ç”¨æ¥å£13: /fbmain/monitor/v3/article_html
"""

import requests
import json
import time
import os
from datetime import datetime

class HTMLContentFetcher:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://www.dajiala.com"
        self.session = requests.Session()

    def test_single_article(self, article_url: str) -> dict:
        """æµ‹è¯•å•ç¯‡æ–‡ç« çš„HTMLå†…å®¹è·å–"""
        print(f"ğŸ§ª æµ‹è¯•è·å–æ–‡ç« HTMLå†…å®¹...")
        print(f"ğŸ“‹ æ–‡ç« URL: {article_url}")
        
        # ä½¿ç”¨æ­£ç¡®çš„HTMLæ¥å£
        url = f"{self.base_url}/fbmain/monitor/v3/article_html"
        params = {
            'key': self.api_key,
            'url': article_url
        }
        
        try:
            print(f"ğŸ”— è°ƒç”¨æ¥å£: {url}")
            print(f"ğŸ“Š å‚æ•°: {params}")
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            print(f"âœ… HTTPçŠ¶æ€ç : {response.status_code}")
            
            result = response.json()
            print(f"ğŸ“„ APIå“åº”: {json.dumps(result, ensure_ascii=False, indent=2)[:500]}...")
            
            if result.get('code') == 0:
                data = result.get('data', {})
                content = data.get('html', '')  # ä¿®æ­£ï¼šä½¿ç”¨htmlå­—æ®µ
                
                print(f"âœ… æˆåŠŸè·å–HTMLå†…å®¹!")
                print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"ğŸ“ å†…å®¹é¢„è§ˆ: {content[:200]}...")
                
                return data
            else:
                print(f"âŒ APIè¿”å›é”™è¯¯: code={result.get('code')}, msg={result.get('msg')}")
                return {}
                
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return {}

    def get_articles_with_html_content(self, sync_file: str, test_only: bool = False):
        """ä¸ºæ–‡ç« è·å–HTMLå†…å®¹"""
        
        print(f"ğŸš€ å¼€å§‹è·å–æ–‡ç« HTMLå†…å®¹...")
        print(f"ğŸ“ åŒæ­¥æ–‡ä»¶: {sync_file}")
        
        # è¯»å–åŒæ­¥æ•°æ®
        with open(sync_file, 'r', encoding='utf-8') as f:
            sync_data = json.load(f)
        
        if test_only:
            # åªæµ‹è¯•ç¬¬ä¸€ç¯‡æ–‡ç« 
            first_article = None
            for account in sync_data['account_results']:
                if account['articles']:
                    first_article = account['articles'][0]
                    break
            
            if first_article and first_article.get('original_url'):
                print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼: åªæµ‹è¯•ç¬¬ä¸€ç¯‡æ–‡ç« ")
                return self.test_single_article(first_article['original_url'])
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯æµ‹è¯•çš„æ–‡ç« ")
                return
        
        total_articles = 0
        success_count = 0
        total_cost = 0.0
        
        # éå†æ‰€æœ‰æ–‡ç« 
        for account_idx, account in enumerate(sync_data['account_results']):
            account_name = account['account_name']
            print(f"\nğŸ“° å¤„ç†è´¦æˆ·: {account_name}")
            
            for article_idx, article in enumerate(account['articles'][:5]):  # å…ˆæµ‹è¯•æ¯ä¸ªè´¦æˆ·çš„å‰5ç¯‡
                total_articles += 1
                article_url = article.get('original_url', '')
                article_title = article.get('title', 'N/A')
                
                if not article_url:
                    print(f"  âš ï¸ è·³è¿‡ï¼ˆæ— URLï¼‰: {article_title[:50]}...")
                    continue
                
                print(f"  ğŸ” [{article_idx+1}] {article_title[:50]}...")
                
                # ä½¿ç”¨æ­£ç¡®çš„HTMLæ¥å£
                url = f"{self.base_url}/fbmain/monitor/v3/article_html"
                params = {
                    'key': self.api_key,
                    'url': article_url
                }
                
                try:
                    response = self.session.get(url, params=params, timeout=30)
                    response.raise_for_status()
                    
                    result = response.json()
                    
                    if result.get('code') == 0:
                        data = result.get('data', {})
                        html_content = data.get('html', '')  # ä¿®æ­£ï¼šä½¿ç”¨htmlå­—æ®µè€Œä¸æ˜¯contentå­—æ®µ
                        
                        if html_content and len(html_content) > 100:
                            # æ›´æ–°æ–‡ç« å†…å®¹
                            article['content_html'] = html_content
                            article['content'] = html_content  # ä¿å­˜HTMLæ ¼å¼
                            
                            # ç”Ÿæˆçº¯æ–‡æœ¬æ‘˜è¦
                            import re
                            plain_text = re.sub(r'<[^>]+>', '', html_content)
                            plain_text = plain_text.replace('&nbsp;', ' ').replace('&lt;', '<').replace('&gt;', '>')
                            article['excerpt'] = plain_text[:300].strip() + ('...' if len(plain_text) > 300 else '')
                            
                            success_count += 1
                            total_cost += 0.04  # HTMLæ¥å£è´¹ç”¨
                            
                            print(f"    âœ… æˆåŠŸ! é•¿åº¦: {len(html_content)} å­—ç¬¦")
                        else:
                            print(f"    âš ï¸ å†…å®¹ä¸ºç©º")
                    else:
                        error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
                        print(f"    âŒ å¤±è´¥: {error_msg}")
                        
                except Exception as e:
                    print(f"    âŒ å¼‚å¸¸: {e}")
                
                # é¿å…è¯·æ±‚è¿‡é¢‘
                time.sleep(1.5)
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        updated_filename = sync_file.replace('.json', '_with_html.json')
        with open(updated_filename, 'w', encoding='utf-8') as f:
            json.dump(sync_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
        print(f"   æ€»æ–‡ç« æ•°: {total_articles}")
        print(f"   æˆåŠŸè·å–: {success_count}")
        print(f"   æˆåŠŸç‡: {success_count/total_articles*100:.1f}%" if total_articles > 0 else "0%")
        print(f"   æ€»è´¹ç”¨: {total_cost:.2f}å…ƒ")
        print(f"   ä¿å­˜åˆ°: {updated_filename}")

def main():
    """ä¸»å‡½æ•°"""
    API_KEY = "JZLebac614e9c88d8b4"
    
    # æŸ¥æ‰¾æœ€æ–°çš„åŒæ­¥æ–‡ä»¶
    sync_files = [f for f in os.listdir('.') if f.startswith('sync_results_') and f.endswith('.json') and 'html' not in f]
    if not sync_files:
        print("âŒ æœªæ‰¾åˆ°åŒæ­¥ç»“æœæ–‡ä»¶")
        return
    
    latest_file = sorted(sync_files)[-1]
    print(f"ğŸ¯ ä½¿ç”¨æ–‡ä»¶: {latest_file}")
    
    fetcher = HTMLContentFetcher(API_KEY)
    
    # å…ˆæµ‹è¯•ä¸€ç¯‡æ–‡ç« 
    print("ğŸ§ª å…ˆæµ‹è¯•ä¸€ç¯‡æ–‡ç« çš„è·å–æ•ˆæœ...")
    test_result = fetcher.get_articles_with_html_content(latest_file, test_only=True)
    
    if test_result and test_result.get('content'):
        print("\nâœ… æµ‹è¯•æˆåŠŸ! æ˜¯å¦ç»§ç»­è·å–æ‰€æœ‰æ–‡ç« çš„HTMLå†…å®¹ï¼Ÿ")
        response = input("ç»§ç»­ï¼Ÿ(y/n): ")
        if response.lower() == 'y':
            fetcher.get_articles_with_html_content(latest_file, test_only=False)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®æˆ–æ–‡ç« é“¾æ¥")

if __name__ == "__main__":
    main()
